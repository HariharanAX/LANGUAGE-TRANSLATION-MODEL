# ğŸŒ Language Translation Model using Encoder-Decoder Architecture

This project implements a **Neural Machine Translation (NMT)** system using an **Encoder-Decoder architecture with LSTM** layers to translate text from one language to another. The model is built using **TensorFlow** and served via a **Flask web app** with a simple frontend interface.

## ğŸš€ Features

- ğŸ”¤ Translates text between supported languages
- ğŸ§  Built with LSTM-based encoder-decoder architecture
- ğŸ—‚ï¸ Preprocessing pipeline for tokenization, padding, and word embedding
- ğŸŒ Interactive UI using **Flask**, **HTML**, **CSS**
- ğŸ“¦ Deployable and easy to use locally

## ğŸ› ï¸ Tech Stack

- **Languages:** Python  
- **Libraries:** TensorFlow, NumPy, Pandas, Flask  
- **Frontend:** HTML, CSS  
- **Other Tools:** Jupyter Notebook, VS Code

## ğŸ“Š Model Architecture

- **Encoder:** Embedding Layer â†’ LSTM
- **Decoder:** Embedding Layer â†’ LSTM â†’ Dense
- **Training:** Sequence-to-sequence learning using teacher forcing

## ğŸ“‚ Folder Structure

