# 🌐 Language Translation Model using Encoder-Decoder Architecture

This project implements a **Neural Machine Translation (NMT)** system using an **Encoder-Decoder architecture with LSTM** layers to translate text from one language to another. The model is built using **TensorFlow** and served via a **Flask web app** with a simple frontend interface.

## 🚀 Features

- 🔤 Translates text between supported languages
- 🧠 Built with LSTM-based encoder-decoder architecture
- 🗂️ Preprocessing pipeline for tokenization, padding, and word embedding
- 🌐 Interactive UI using **Flask**, **HTML**, **CSS**
- 📦 Deployable and easy to use locally

## 🛠️ Tech Stack

- **Languages:** Python  
- **Libraries:** TensorFlow, NumPy, Pandas, Flask  
- **Frontend:** HTML, CSS  
- **Other Tools:** Jupyter Notebook, VS Code

## 📊 Model Architecture

- **Encoder:** Embedding Layer → LSTM
- **Decoder:** Embedding Layer → LSTM → Dense
- **Training:** Sequence-to-sequence learning using teacher forcing

## 📂 Folder Structure

